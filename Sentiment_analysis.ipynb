{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afaa98f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries, APIS & Tensorflow\n",
    "\n",
    "# import future\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b4f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow & keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ed3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules, libraries, APIs, optimizers, layers, etc...\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    MaxPool1D\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f8c9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e88614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b7b4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.applications import VGG16, xception\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1feb755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import scipy\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sn\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from contextlib import redirect_stdout\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a9ed650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the File: ipykernel_launcher.py\n"
     ]
    }
   ],
   "source": [
    "# print file name\n",
    "\n",
    "file_name =  os.path.basename(sys.argv[0])\n",
    "file_name = str(file_name)\n",
    "\n",
    "print(\"Name of the File:\", file_name)\n",
    "\n",
    "# Trim the \".py\" extensiojn from the file \n",
    "\n",
    "file_name = file_name[:-3]\n",
    "\n",
    "# set another (very high) limit for image processing\n",
    "\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 9933120000\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "523600bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list where the accuracy rates of each dataset will be stored\n",
    "\n",
    "list_acc_rates = list()\n",
    "\n",
    "# set the number of frozen layers that will not be trained\n",
    "\n",
    "num_freeze = 132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcf8069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the paths, pathfiles\n",
    "\n",
    "parent_dir = \"C:/Users/Teclast/Documents/Papers/Deep Learning in Artworks/Database/\"\n",
    "path_train_images = parent_dir\n",
    "saved_model_path = \"C:/Users/Teclast/Documents/Papers/Deep Learning in Artworks/Experiments/Sentiment/Sentiment_model_performance/\"\n",
    "path_scripts = \"C:/Users/Teclast/Documents/Papers/Deep Learning in Artworks/Experiments/Sentiment/Sentiment_model_architecture/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11677210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher_df(1)\n",
      "            Artist_Name                               File_Name    Art_Class  \\\n",
      "0  Alphonse Maria Mucha  alphonse-mucha_6th-sokol-festival-1912  Art Nouveau   \n",
      "1  Alphonse Maria Mucha  alphonse-mucha_8th-sokol-festival-1912  Art Nouveau   \n",
      "2  Alphonse Maria Mucha                      alphonse-mucha_aaw  Art Nouveau   \n",
      "\n",
      "  Emotion_Class  Joy  Sadness  Disgust  Surprise  Anger  Fear  \n",
      "0       Disgust    0        0        1         0      0     0  \n",
      "1           Joy    1        0        0         0      0     0  \n",
      "2           Joy    1        0        0         0      0     0  \n",
      "(15292, 10)\n"
     ]
    }
   ],
   "source": [
    "meganum = 1\n",
    "num_dataset = 1\n",
    "\n",
    "new_file_name = file_name + \"_df(\" + str(meganum) + \")\"\n",
    "print(new_file_name)\n",
    "\n",
    "train_labels_path = parent_dir + \"Labels/\" + \"Emotion_set_\" + str(num_dataset) +\".xlsx\"\n",
    "\n",
    "### Setting up all the parameters for the training, processing of data and produced files management ###\n",
    "\n",
    "### setting parameters for the saving and loading of produced files ###\n",
    "\n",
    "# set batch size\n",
    "\n",
    "# num_batch = 10\n",
    "\n",
    "# adjusting the size of images into the same dimensions\n",
    "\n",
    "img_width = 71\n",
    "img_height = 71\n",
    "\n",
    "# adjsusting training parameters\n",
    "\n",
    "lrn_rate = 0.0001  # learning rate\n",
    "num_epochs = 5  # number of training epochs\n",
    "act_func = \"sigmoid\"  # activation fuction\n",
    "\n",
    "num_neurons_1st_dense = 100 # number of neurons in first dense layer\n",
    "drop_perc_1st_dense = 0 # percentage of dropout rate in first dense layer\n",
    "\n",
    "num_neurons_2nd_dense = 50 # number of neurons in second dense layer\n",
    "drop_perc_2nd_dense = 0 # percentage of dropout rate in second dense layer\n",
    "\n",
    "num_neurons_3d_dense = 0 # number of neurons in second dense layer\n",
    "drop_perc_3d_dense = 0 # percentage of dropout rate in second dense layer\n",
    "\n",
    "# import the labels of the dataset\n",
    "\n",
    "data = pd.read_excel(train_labels_path, engine=\"openpyxl\")\n",
    "\n",
    "# check the dataframe to inspect any NaNs or missing values\n",
    "\n",
    "print(data.head(3))\n",
    "\n",
    "# check the number of rows and columns of the dataframe\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b981cb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15292/15292 [11:39<00:00, 21.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X list is:  (15292, 71, 71, 3)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "\n",
    "# attach the images with the labels, in order to have supervised learning and convert them to have values between 0 - 1 by multiplying with 255 (RGB values: 0 - 255)\n",
    "\n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    path = (\n",
    "        path_train_images\n",
    "        + data[\"Art_Class\"][i]\n",
    "        + \"/\"\n",
    "        + data[\"Artist_Name\"][i]\n",
    "        + \"/\"\n",
    "        + data[\"File_Name\"][i]\n",
    "        + \".jpg\"\n",
    "    )\n",
    "    img = image.load_img(path, target_size=(img_width, img_height, 3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    X.append(img)\n",
    "\n",
    "\n",
    "# convert images into np array\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "# get the size of dataframe X\n",
    "\n",
    "print(\"The shape of X list is: \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "964fd248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is:  (10703, 71, 71, 3)\n",
      "The shape of y_train is:  (10703, 6)\n",
      "The shape of X_test is:  (3059, 71, 71, 3)\n",
      "The shape of y_test is:  (3059, 6)\n",
      "The shape of X_val is:  (1530, 71, 71, 3)\n",
      "The shape of y_val is:  (1530, 6)\n"
     ]
    }
   ],
   "source": [
    "y_starting = data\n",
    "\n",
    "# create the train/test sets, set the size of test set\n",
    "\n",
    "X_train, X_test, y_starting_train, y_starting_test = train_test_split(X, y_starting, test_size=0.2, random_state=1)\n",
    "\n",
    "# create the test/validation sets, set the size of validation set\n",
    "\n",
    "X_train, X_val, y_starting_train, y_starting_val = train_test_split(X_train, y_starting_train, test_size=0.125, random_state=1)\n",
    "\n",
    "# removing \"unnecessary columns, in order to have only the one-hot encoded columns for the training\n",
    "\n",
    "y_train = y_starting_train.drop([\"Artist_Name\", \"File_Name\", \"Art_Class\", \"Emotion_Class\"], axis=1)\n",
    "y_test = y_starting_test.drop([\"Artist_Name\", \"File_Name\", \"Art_Class\", \"Emotion_Class\"], axis=1)\n",
    "y_val = y_starting_val.drop([\"Artist_Name\", \"File_Name\", \"Art_Class\", \"Emotion_Class\"], axis=1)\n",
    "\n",
    "# set that the evaluation set is 10% of the total dataset\n",
    "# the testing dataset will be 20% of the total dataset\n",
    "# the final percentage of training set will be 70% of the total dataset\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# get the shapes of train, test and validation splits\n",
    "\n",
    "print(\"The shape of X_train is: \", X_train.shape)\n",
    "print(\"The shape of y_train is: \", y_train.shape)\n",
    "\n",
    "print(\"The shape of X_test is: \", X_test.shape)\n",
    "print(\"The shape of y_test is: \", y_test.shape)\n",
    "\n",
    "print(\"The shape of X_val is: \", X_val.shape)\n",
    "print(\"The shape of y_val is: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e74cd42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df278b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e0bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc47a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cc9f4d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_4 False\n",
      "block1_conv1 False\n",
      "block1_conv1_bn False\n",
      "block1_conv1_act False\n",
      "block1_conv2 False\n",
      "block1_conv2_bn False\n",
      "block1_conv2_act False\n",
      "block2_sepconv1 False\n",
      "block2_sepconv1_bn False\n",
      "block2_sepconv2_act False\n",
      "block2_sepconv2 False\n",
      "block2_sepconv2_bn False\n",
      "conv2d_12 False\n",
      "block2_pool False\n",
      "batch_normalization_12 False\n",
      "add_36 False\n",
      "block3_sepconv1_act False\n",
      "block3_sepconv1 False\n",
      "block3_sepconv1_bn False\n",
      "block3_sepconv2_act False\n",
      "block3_sepconv2 False\n",
      "block3_sepconv2_bn False\n",
      "conv2d_13 False\n",
      "block3_pool False\n",
      "batch_normalization_13 False\n",
      "add_37 False\n",
      "block4_sepconv1_act False\n",
      "block4_sepconv1 False\n",
      "block4_sepconv1_bn False\n",
      "block4_sepconv2_act False\n",
      "block4_sepconv2 False\n",
      "block4_sepconv2_bn False\n",
      "conv2d_14 False\n",
      "block4_pool False\n",
      "batch_normalization_14 False\n",
      "add_38 False\n",
      "block5_sepconv1_act False\n",
      "block5_sepconv1 False\n",
      "block5_sepconv1_bn False\n",
      "block5_sepconv2_act False\n",
      "block5_sepconv2 False\n",
      "block5_sepconv2_bn False\n",
      "block5_sepconv3_act False\n",
      "block5_sepconv3 False\n",
      "block5_sepconv3_bn False\n",
      "add_39 False\n",
      "block6_sepconv1_act False\n",
      "block6_sepconv1 False\n",
      "block6_sepconv1_bn False\n",
      "block6_sepconv2_act False\n",
      "block6_sepconv2 False\n",
      "block6_sepconv2_bn False\n",
      "block6_sepconv3_act False\n",
      "block6_sepconv3 False\n",
      "block6_sepconv3_bn False\n",
      "add_40 False\n",
      "block7_sepconv1_act False\n",
      "block7_sepconv1 False\n",
      "block7_sepconv1_bn False\n",
      "block7_sepconv2_act False\n",
      "block7_sepconv2 False\n",
      "block7_sepconv2_bn False\n",
      "block7_sepconv3_act False\n",
      "block7_sepconv3 False\n",
      "block7_sepconv3_bn False\n",
      "add_41 False\n",
      "block8_sepconv1_act False\n",
      "block8_sepconv1 False\n",
      "block8_sepconv1_bn False\n",
      "block8_sepconv2_act False\n",
      "block8_sepconv2 False\n",
      "block8_sepconv2_bn False\n",
      "block8_sepconv3_act False\n",
      "block8_sepconv3 False\n",
      "block8_sepconv3_bn False\n",
      "add_42 False\n",
      "block9_sepconv1_act False\n",
      "block9_sepconv1 False\n",
      "block9_sepconv1_bn False\n",
      "block9_sepconv2_act False\n",
      "block9_sepconv2 False\n",
      "block9_sepconv2_bn False\n",
      "block9_sepconv3_act False\n",
      "block9_sepconv3 False\n",
      "block9_sepconv3_bn False\n",
      "add_43 False\n",
      "block10_sepconv1_act False\n",
      "block10_sepconv1 False\n",
      "block10_sepconv1_bn False\n",
      "block10_sepconv2_act False\n",
      "block10_sepconv2 False\n",
      "block10_sepconv2_bn False\n",
      "block10_sepconv3_act False\n",
      "block10_sepconv3 False\n",
      "block10_sepconv3_bn False\n",
      "add_44 False\n",
      "block11_sepconv1_act False\n",
      "block11_sepconv1 False\n",
      "block11_sepconv1_bn False\n",
      "block11_sepconv2_act False\n",
      "block11_sepconv2 False\n",
      "block11_sepconv2_bn False\n",
      "block11_sepconv3_act False\n",
      "block11_sepconv3 False\n",
      "block11_sepconv3_bn False\n",
      "add_45 False\n",
      "block12_sepconv1_act False\n",
      "block12_sepconv1 False\n",
      "block12_sepconv1_bn False\n",
      "block12_sepconv2_act False\n",
      "block12_sepconv2 False\n",
      "block12_sepconv2_bn False\n",
      "block12_sepconv3_act False\n",
      "block12_sepconv3 False\n",
      "block12_sepconv3_bn False\n",
      "add_46 False\n",
      "block13_sepconv1_act False\n",
      "block13_sepconv1 False\n",
      "block13_sepconv1_bn False\n",
      "block13_sepconv2_act False\n",
      "block13_sepconv2 False\n",
      "block13_sepconv2_bn False\n",
      "conv2d_15 False\n",
      "block13_pool False\n",
      "batch_normalization_15 False\n",
      "add_47 False\n",
      "block14_sepconv1 False\n",
      "block14_sepconv1_bn False\n",
      "block14_sepconv1_act False\n",
      "block14_sepconv2 False\n",
      "block14_sepconv2_bn False\n",
      "block14_sepconv2_act False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               1843300   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 22,710,136\n",
      "Trainable params: 1,848,656\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the Xception model\n",
    "\n",
    "xception_conv = xception.Xception(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# we chose blocks, we will freeze in order to adopt the train weights\n",
    "# unfreeze the rest:\n",
    "\n",
    "for layer in xception_conv.layers[:num_freeze]:\n",
    "  layer.trainable = False\n",
    "\n",
    "for layer in xception_conv.layers[num_freeze:]:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "\n",
    "for layer in xception_conv.layers:\n",
    "    print(layer.name, layer.trainable)\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the Xception convolutional base model\n",
    "\n",
    "model.add(xception_conv)\n",
    "\n",
    "# flatten all layers\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Add new layers\n",
    "\n",
    "# Add first additional dense layer\n",
    "\n",
    "model.add(layers.Dense(num_neurons_1st_dense, activation='relu'))\n",
    "#model.add(layers.Dropout(drop_perc_1st_dense))\n",
    "\n",
    "# Add second additional dense layer\n",
    "\n",
    "model.add(layers.Dense(num_neurons_2nd_dense, activation='relu'))\n",
    "#model.add(layers.Dropout(drop_perc_2nd_dense))\n",
    "\n",
    "# Add third additional dense layer (if needed)\n",
    "\n",
    "#model.add(layers.Dense(num_neurons_3d_dense, activation='relu'))\n",
    "#model.add(layers.Dropout(drop_perc_3d_dense))\n",
    "\n",
    "model.add(layers.Dense(6\n",
    ", activation= act_func))\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "\n",
    "model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "684fde3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xception_conv.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "095cdd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 11/536 [..............................] - ETA: 36:55 - loss: 0.5377 - acc: 0.2409"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m RMSprop(lr\u001b[38;5;241m=\u001b[39mlrn_rate),\n\u001b[0;32m      4\u001b[0m             loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m             metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1098\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraceContext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1093\u001b[0m     graph_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1094\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1095\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1096\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size):\n\u001b[0;32m   1097\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1098\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1100\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 780\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tracing_count()\n\u001b[0;32m    783\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:807\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    804\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    805\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    806\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    809\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    810\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2829\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2828\u001b[0m   graph_function, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filtered_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1843\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_filtered_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, kwargs, cancellation_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1828\u001b[0m   \u001b[38;5;124;03m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m \n\u001b[0;32m   1830\u001b[0m \u001b[38;5;124;03m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;124;03m    `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1843\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1844\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1846\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseResourceVariable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1847\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1923\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1918\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1919\u001b[0m     pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1921\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1922\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1923\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1924\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1925\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m     args,\n\u001b[0;32m   1927\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1928\u001b[0m     executing_eagerly)\n\u001b[0;32m   1929\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:545\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    544\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 545\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    554\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    557\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    558\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\Anaconda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=lrn_rate),\n",
    "            loss = 'binary_crossentropy',\n",
    "            metrics = ['acc'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "            batch_size=20,\n",
    "            epochs=num_epochs,\n",
    "            validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45c669f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.70980394, 0.627451  , 0.54509807],\n",
       "        [0.7764706 , 0.69803923, 0.6039216 ],\n",
       "        [0.80784315, 0.70980394, 0.6313726 ],\n",
       "        ...,\n",
       "        [0.62352943, 0.5372549 , 0.54509807],\n",
       "        [0.5921569 , 0.5176471 , 0.53333336],\n",
       "        [0.74509805, 0.6431373 , 0.6392157 ]],\n",
       "\n",
       "       [[0.84705883, 0.78039217, 0.70980394],\n",
       "        [0.79607844, 0.7294118 , 0.6666667 ],\n",
       "        [0.7176471 , 0.6509804 , 0.5882353 ],\n",
       "        ...,\n",
       "        [0.7921569 , 0.69803923, 0.7490196 ],\n",
       "        [0.67058825, 0.5764706 , 0.6313726 ],\n",
       "        [0.72156864, 0.627451  , 0.6784314 ]],\n",
       "\n",
       "       [[0.8039216 , 0.7490196 , 0.7137255 ],\n",
       "        [0.80784315, 0.7411765 , 0.70980394],\n",
       "        [0.77254903, 0.68235296, 0.627451  ],\n",
       "        ...,\n",
       "        [0.7411765 , 0.654902  , 0.6627451 ],\n",
       "        [0.73333335, 0.65882355, 0.6745098 ],\n",
       "        [0.7490196 , 0.6745098 , 0.69803923]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.69803923, 0.6862745 , 0.6509804 ],\n",
       "        [0.14117648, 0.14901961, 0.06666667],\n",
       "        [0.3019608 , 0.2901961 , 0.21568628],\n",
       "        ...,\n",
       "        [0.6627451 , 0.61960787, 0.6117647 ],\n",
       "        [0.5647059 , 0.52156866, 0.5137255 ],\n",
       "        [0.5372549 , 0.49411765, 0.4862745 ]],\n",
       "\n",
       "       [[0.18039216, 0.17254902, 0.11372549],\n",
       "        [0.44705883, 0.41960785, 0.30980393],\n",
       "        [0.5529412 , 0.53333336, 0.45490196],\n",
       "        ...,\n",
       "        [0.42352942, 0.3764706 , 0.3764706 ],\n",
       "        [0.5803922 , 0.53333336, 0.53333336],\n",
       "        [0.46666667, 0.42352942, 0.41568628]],\n",
       "\n",
       "       [[0.34509805, 0.34117648, 0.27058825],\n",
       "        [0.60784316, 0.5686275 , 0.52156866],\n",
       "        [0.41960785, 0.4117647 , 0.32156864],\n",
       "        ...,\n",
       "        [0.5882353 , 0.5411765 , 0.5568628 ],\n",
       "        [0.5254902 , 0.47843137, 0.47843137],\n",
       "        [0.49411765, 0.44705883, 0.45490196]]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a5bf463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Art_Class</th>\n",
       "      <th>True_Emotion_Class</th>\n",
       "      <th>Predicted_Emotion_1</th>\n",
       "      <th>Predicted_Emotion_2</th>\n",
       "      <th>Predicted_Emotion_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Artist_Name, File_Name, Art_Class, True_Emotion_Class, Predicted_Emotion_1, Predicted_Emotion_2, Predicted_Emotion_3]\n",
       "Index: []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repair = pd.read_excel('C:/Users/Teclast/Desktop/Repair.xlsx',engine = 'openpyxl')\n",
    "df_repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c0452cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Art_Class</th>\n",
       "      <th>True_Emotion_Class</th>\n",
       "      <th>Predicted_Emotion_1</th>\n",
       "      <th>Predicted_Emotion_2</th>\n",
       "      <th>Predicted_Emotion_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>Juan Gris</td>\n",
       "      <td>juan-gris_the-violin-1914</td>\n",
       "      <td>Cubism</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8864</th>\n",
       "      <td>Gustave Loiseau</td>\n",
       "      <td>gustave-loiseau_by-the-eure-river</td>\n",
       "      <td>Post-Impressionism</td>\n",
       "      <td>Joy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14868</th>\n",
       "      <td>Salvador Dali</td>\n",
       "      <td>salvador-dali_portrait-of-colonel-jack-warner</td>\n",
       "      <td>Surrealism</td>\n",
       "      <td>Joy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Artist_Name                                      File_Name  \\\n",
       "2648         Juan Gris                      juan-gris_the-violin-1914   \n",
       "8864   Gustave Loiseau              gustave-loiseau_by-the-eure-river   \n",
       "14868    Salvador Dali  salvador-dali_portrait-of-colonel-jack-warner   \n",
       "\n",
       "                Art_Class True_Emotion_Class Predicted_Emotion_1  \\\n",
       "2648               Cubism            Sadness                 NaN   \n",
       "8864   Post-Impressionism                Joy                 NaN   \n",
       "14868          Surrealism                Joy                 NaN   \n",
       "\n",
       "      Predicted_Emotion_2 Predicted_Emotion_3  \n",
       "2648                  NaN                 NaN  \n",
       "8864                  NaN                 NaN  \n",
       "14868                 NaN                 NaN  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repair['Artist_Name'] = y_starting_val['Artist_Name']\n",
    "df_repair['File_Name'] = y_starting_val['File_Name']\n",
    "df_repair['Art_Class'] = y_starting_val['Art_Class']\n",
    "df_repair['True_Emotion_Class'] = y_starting_val['Emotion_Class']\n",
    "\n",
    "df_repair.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cdae1ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted_Emotion_1\n",
      "<class 'str'>\n",
      "Predicted_Emotion_2\n",
      "<class 'str'>\n",
      "Predicted_Emotion_3\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    column_name = 'Predicted_Emotion_' + str(i)\n",
    "    print(column_name)\n",
    "    print(type(column_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "395891f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2648     NaN\n",
       "8864     NaN\n",
       "14868    NaN\n",
       "3994     NaN\n",
       "503      NaN\n",
       "        ... \n",
       "4272     NaN\n",
       "154      NaN\n",
       "14110    NaN\n",
       "11556    NaN\n",
       "1819     NaN\n",
       "Name: Predicted_Emotion_3, Length: 1530, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repair[column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee2a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
